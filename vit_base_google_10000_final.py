# -*- coding: utf-8 -*-
"""VIT-base google 10000_final

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bEZoDP_I5qHgLrxbcY_78r1MDH74V1E_
"""

#EDA
# El conjunto de datos cuenta con dos carpetas, una que contiene 5 datasets y
# otra con la totalidad de las fotografías etiquetadas y un dataset de las mismas.
# Empezamos haciendo una exploración incial de los datasets para entender qué puede sernos útil.

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
  print('Not using a high-RAM runtime')
else:
  print('You are using a high-RAM runtime!')

from google.colab import drive
drive.mount('/content/drive')

import json
import numpy as np
import matplotlib.pyplot as plt
import os
import tensorflow as tf
import pandas as pd

# #Limitamos el consumo de VRAM de la GPU
# gpus = tf.config.experimental.list_physical_devices('GPU')
# for gpu in gpus:
#   tf.config.experimental.set_memory_growth(gpu, True)

# gpus = tf.config.experimental.list_physical_devices('GPU')
# gpus

!tar -xvf "/content/drive/Shareddrives/Proyecto_Final/Datasets/Photos_comprimido/yelp_photos.tar" -C "/content"

import os
import shutil
import cv2
from google.colab.patches import cv2_imshow
import os.path


if not os.path.exists('/content/train/inside'):
  os.mkdir('/content/train/inside')
if not os.path.exists('/content/train/outside'):
  os.mkdir('/content/train/outside')
if not os.path.exists('/content/train/food'):
  os.mkdir('/content/train/food')
if not os.path.exists('/content/train/menu'):
  os.mkdir('/content/train/menu')
if not os.path.exists('/content/train/drink'):
  os.mkdir('/content/train/drink')

import shutil

n = 10000
n_food = n*0.54
n_inside = n*0.28
n_outside = n*0.078
n_drink = n*0.093
n_menu = n*0.0084

n_food_aux = 0
n_inside_aux = 0
n_outside_aux = 0
n_drink_aux = 0
n_menu_aux = 0

for index, row in json_file.iterrows():
    label = row['label']
    photo_id = row['photo_id']
    if label == "menu" and n_menu_aux<n_menu:
        shutil.copy2(os.path.join(os.sep, "content", "photos", f"{photo_id}.jpg"), os.path.join(os.sep, "content", "train", "menu", f"{photo_id}.jpg"))
        n_menu_aux = n_menu_aux + 1
    if label == "food" and n_food_aux<n_food:
        shutil.copy2(os.path.join(os.sep, "content", "photos", f"{photo_id}.jpg"), os.path.join(os.sep, "content", "train", "food", f"{photo_id}.jpg"))
        n_food_aux = n_food_aux + 1
    if label == "inside" and n_inside_aux<n_inside:
        shutil.copy2(os.path.join(os.sep, "content", "photos", f"{photo_id}.jpg"), os.path.join(os.sep, "content", "train", "inside", f"{photo_id}.jpg"))
        n_inside_aux_aux = n_inside_aux + 1
    if label == "outside" and n_outside_aux < n_outside:
        shutil.copy2(os.path.join(os.sep, "content", "photos", f"{photo_id}.jpg"), os.path.join(os.sep, "content", "train", "outside", f"{photo_id}.jpg"))
        n_outside_aux = n_outside_aux + 1
    if label == "drink" and n_drink_aux < n_drink:
        shutil.copy2(os.path.join(os.sep, "content", "photos", f"{photo_id}.jpg"), os.path.join(os.sep, "content", "train", "drink", f"{photo_id}.jpg"))
        n_drink_aux = n_drink_aux + 1

import os
import shutil
import cv2
from google.colab.patches import cv2_imshow
import os.path

content_dir_1 = "/content/train/inside"
for filename in os.listdir(content_dir_1):
    im_path = os.path.join(content_dir_1, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)

content_dir_2 = "/content/train/outside"
for filename in os.listdir(content_dir_2):
    im_path = os.path.join(content_dir_2, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)

content_dir_3 = "/content/train/food"
for filename in os.listdir(content_dir_3):
    im_path = os.path.join(content_dir_3, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)

content_dir_4 = "/content/train/drink"
for filename in os.listdir(content_dir_4):
    im_path = os.path.join(content_dir_4, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)

content_dir_5 = "/content/train/menu"
for filename in os.listdir(content_dir_5):
    im_path = os.path.join(content_dir_5, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)



import os
import random
folder= "/content/train/inside"
files = os.listdir(folder)  # Get filenames in current folder
files = random.sample(files, 50000)  # Pick 900 random files
for file in files:  # Go over each file name to be deleted
      f = os.path.join(folder, file)  # Create valid path to file
      os.remove(f)  # Remove the file

import cv2
import  os

from google.colab.patches import cv2_imshow
image = cv2.imread('/content/photos/mXivoKI_GkmX87E-7jczBw.jpg')
cv2_imshow(image)

json_file = pd.read_json('/content/drive/Shareddrives/Proyecto_Final/Datasets/Photos/yelp_photos/photos.json', lines=True)

json_file = json_file[["photo_id", "label"]]

import os
import shutil

n = 10000
n_food = n*0.54
n_inside = n*0.28
n_outside = n*0.078
n_drink = n*0.093
n_menu = n*0.0084

n_food_aux = 0
n_inside_aux = 0
n_outside_aux = 0
n_drink_aux = 0
n_menu_aux = 0

for index, row in json_file.iterrows():
    label = row['label']
    photo_id = row['photo_id']
    try:
        if label == "menu" and n_menu_aux<n_menu:
            shutil.copyfile("/content/photos/" +photo_id + ".jpg", "/content/menu/" + photo_id + ".jpg")
            n_menu_aux = n_menu_aux + 1
        if label == "food" and n_food_aux<n_food:
            shutil.copyfile("/content/photos/" +photo_id + ".jpg", "/content/food/" + photo_id + ".jpg")
            n_food_aux = n_food_aux + 1
        if label == "inside" and n_inside_aux<n_inside:
            shutil.copyfile("/content/photos/" +photo_id + ".jpg", "/content/inside/" + photo_id + ".jpg")
            n_inside_aux = n_inside_aux + 1
        if label == "outside" and n_outside_aux < n_outside:
            shutil.copyfile("/content/photos/" +photo_id + ".jpg", "/content/outside/" + photo_id + ".jpg")
            n_outside_aux = n_outside_aux + 1
        if label == "drink" and n_drink_aux < n_drink:
            shutil.copyfile("/content/photos/" +photo_id + ".jpg", "/content/drink/" + photo_id + ".jpg")
            n_drink_aux = n_drink_aux + 1
    except FileNotFoundError:
        print("El archivo", photo_id, "no se encuentra en la ruta especificada.")

total_count = json_file[["label"]].count()
print(total_count)
print("food: " + str(108152/total_count*100))
print("inside: " + str(56031/total_count*100))
print("drink: " + str(18569/total_count*100))
print("outside: " + str(15670/total_count*100))
print("menu: " + str(1678/total_count*100))
json_file[["label"]].value_counts()



"""# EDA JSONS"""

len(os.listdir('/content/photos'))

#Results

"""Separamos las imágenes según las diferentes etiquetas en carpetas

LIMPIEZA IMAGENES DEFECTUOSAS
"""

content_dir = "/content/inside"
for filename in os.listdir(content_dir):
    im_path = os.path.join(content_dir, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)

content_dir2 = "/content/outside"
for filename in os.listdir(content_dir2):
    im_path = os.path.join(content_dir2, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)

content_dir3 = "/content/food"
for filename in os.listdir(content_dir3):
    im_path = os.path.join(content_dir3, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)

content_dir4= "/content/drink"
for filename in os.listdir(content_dir4):
    im_path = os.path.join(content_dir4, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)

content_dir5 = "/content/menu"
for filename in os.listdir(content_dir5):
    im_path = os.path.join(content_dir5, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)

"""Eliminamos las imagenes duplicadas mediante la libreria hashlib. El codigo agrupa las imagenes que tienen idéntico hash en cada uno de los cinco subdirectorios de etiquetas y elimina las duplicadas quedándose sólo con una foto por cada hash.

"""

import os
import hashlib

def get_hash(file_path):
    with open(file_path, 'rb') as f:
        return hashlib.md5(f.read()).hexdigest()

def group_images_by_hash(directory):
    hashes = {}
    for filename in os.listdir(directory):
        file_path = os.path.join(directory, filename)
        file_hash = get_hash(file_path)
        if file_hash in hashes:
            hashes[file_hash].append(file_path)
        else:
            hashes[file_hash] = [file_path]

    return hashes

def print_grouped_images(grouped_images):
    for hash_value, image_list in grouped_images.items():
        print(f'Hash value: {hash_value}')
        print(f'Number of images: {len(image_list)}')
        print('Image paths:')
        for image in image_list:
            print(f'  - {image}')
        print('')

def remove_images(grouped_images):
    for hash_value, image_list in grouped_images.items():
        if len(image_list) == 1:
            continue
        for image in image_list[1:]:
            os.remove(image)

directories = ['/content/inside', '/content/outside', '/content/food', '/content/menu', '/content/drink']
for directory in directories:
    grouped_images = group_images_by_hash(directory)
    print_grouped_images(grouped_images)
    remove_images(grouped_images)
    grouped_images = group_images_by_hash(directory)
    print_grouped_images(grouped_images)

"""comprobamos el numero total de imagenes post-clean

"""

total_fotos= len(os.listdir('/content/drink'))+len(os.listdir('/content/inside'))+len(os.listdir('/content/outside'))+len(os.listdir('/content/food'))+len(os.listdir('/content/menu'))
total_fotos

"""Sampleamos respetando los pesos muestra de 10000 imagenes y las guardamos en su correspondiente carpeta

IMPORTAMOS LIBRERIAS
"""

import pandas as pd
import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import csv
import os
import random
import numpy as np
from sklearn.model_selection import train_test_split
from PIL import Image



pip install -q transformers

import logging
import os
import sys
from dataclasses import dataclass, field
from typing import Optional

import numpy as np
import torch
from datasets import load_dataset
from PIL import Image
from torchvision.transforms import (
    CenterCrop,
    Compose,
    Normalize,
    RandomHorizontalFlip,
    RandomResizedCrop,
    Resize,
    ToTensor,
)

import transformers
from transformers import (
    MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING,
    AutoConfig,
    AutoImageProcessor,
    AutoModelForImageClassification,
    HfArgumentParser,
    Trainer,
    TrainingArguments,
    set_seed,
)
from transformers.trainer_utils import get_last_checkpoint
from transformers.utils import check_min_version, send_example_telemetry
from transformers.utils.versions import require_version



from sklearn.model_selection import train_test_split
import shutil

# Ruta de tu conjunto de datos original
data_dir = "/content/output"

# Rutas de salida para los conjuntos de entrenamiento y prueba
train_dir = "/content/train"
test_dir = "/content/test"

# Crea los directorios para los conjuntos de entrenamiento y prueba
if not os.path.exists(train_dir):
    os.makedirs(train_dir)
if not os.path.exists(test_dir):
    os.makedirs(test_dir)

# Lista todas las subcarpetas dentro de la carpeta original
subdirs = [subdir for subdir in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, subdir))]

# Crea las subcarpetas correspondientes en los conjuntos de entrenamiento y prueba
for subdir in subdirs:
    subdir_path = os.path.join(data_dir, subdir)
    train_subdir_path = os.path.join(train_dir, subdir)
    test_subdir_path = os.path.join(test_dir, subdir)

    if not os.path.exists(train_subdir_path):
        os.makedirs(train_subdir_path)
    if not os.path.exists(test_subdir_path):
        os.makedirs(test_subdir_path)

    # Obtiene la lista de imágenes para esta clase
    image_files = [os.path.join(subdir_path, filename) for filename in os.listdir(subdir_path) if filename.endswith(".jpg")]

    # Separa las imágenes en conjuntos de entrenamiento y prueba
    train_images, test_images = train_test_split(image_files, test_size=0.2, random_state=42, stratify=[subdir]*len(image_files))
    # Usa train_test_split para dividir las rutas en conjuntos de entrenamiento y prueba
    train_filenames, test_filenames, train_labels, test_labels = train_test_split(
    filenames, labels, test_size=0.2, stratify=labels, random_state=42)

    # Copia las imágenes correspondientes a los conjuntos de entrenamiento y prueba
    for image_path in train_images:
        shutil.copy(image_path, train_subdir_path)
    for image_path in test_images:
        shutil.copy(image_path, test_subdir_path)

  # Verifica que las etiquetas estén balanceadas en ambos conjuntos
print("Número de imágenes de entrenamiento por etiqueta:")
print(np.bincount(train_labels))
print("Número de imágenes de prueba por etiqueta:")
print(np.bincount(test_labels))

# Define los directorios de las etiquetas
outside_photos_dir = "/content/outside"
inside_photos_dir = "/content/inside"
menu_photos_dir = "/content/menu"
drink_photos_dir = "/content/drink"
food_photos_dir = "/content/food"

# Crea una lista de rutas y etiquetas
filenames = []
labels = []
for label, folder in enumerate([outside_photos_dir, inside_photos_dir, menu_photos_dir, drink_photos_dir, food_photos_dir]):
    for filename in os.listdir(folder):
        filenames.append(os.path.join(folder, filename))
        labels.append(label)

# Usa train_test_split para dividir las rutas en conjuntos de entrenamiento y prueba
train_filenames, test_filenames, train_labels, test_labels = train_test_split(
    filenames, labels, test_size=0.2, stratify=labels, random_state=42)

# Cambia el tamaño de las imágenes a (224,224)
def resize_images(filenames):
    resized_images = []
    for filename in filenames:
        image = Image.open(filename)
        image = image.resize((224,224))
        image = np.array(image)
        resized_images.append(image)
    return np.array(resized_images)

train_images = resize_images(train_filenames)
test_images = resize_images(test_filenames)

# Verifica que las etiquetas estén balanceadas en ambos conjuntos
print("Número de imágenes de entrenamiento por etiqueta:")
print(np.bincount(train_labels))
print("Número de imágenes de prueba por etiqueta:")
print(np.bincount(test_labels))

# Commented out IPython magic to ensure Python compatibility.
# %run run_image_classification.py \
    --train_dir "G:\\Mi unidad\\dataset" \
    --output_dir "G:\\Mi unidad\\output" \
    --remove_unused_columns False \
    --do_train \
    --do_eval

train_images.shape

test_images.shape

!pip install evaluate

!pip install -r examples/pytorch/image-classification/requirements.txt

!pip install torch torchvision
!pip install einops
!pip install timm

import os
import pandas as pd
import torch
from PIL import Image
from torch.utils.data import Dataset
import json
import numpy as np
import matplotlib.pyplot as plt
import os
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from torchvision import transforms
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from tqdm import tqdm
import timm
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader

from einops.layers.torch import Rearrange
from timm.models.layers import DropPath
import os
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import torch
import torch.nn as nn
import torch.optim as optim

!pip install transformers

from transformers import AutoImageProcessor, TFViTForImageClassification
import tensorflow as tf
from datasets import load_dataset

import os
import random
import numpy as np
from sklearn.model_selection import train_test_split
import torch
import torchvision.transforms.functional as TF
import torchvision.transforms as transforms
from PIL import Image
from transformers import ViTFeatureExtractor, ViTForImageClassification


# Carga el modelo y el extractor de características
model = ViTForImageClassification.from_pretrained("google/vit-base-patch16-224")
feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')


# Define la función para cargar las imágenes y las etiquetas en el formato necesario para el modelo
def load_images_and_labels(filenames, labels):
    images = []
    for filename in filenames:
        try:
            image = Image.open(filename)
            image = transform(image)
            images.append(image)
        except:
            print(f"Error al cargar la imagen: {filename}")
    images = torch.stack(images)
    labels = torch.tensor(labels)
    return images, labels

# Carga las imágenes de entrenamiento y prueba y sus etiquetas
train_images, train_labels = load_images_and_labels(train_filenames, train_labels)
test_images, test_labels = load_images_and_labels(test_filenames, test_labels)

# Carga las imágenes de entrenamiento y prueba y sus etiquetas
train_images, train_labels = load_images_and_labels(train_filenames, train_labels)
test_images, test_labels = load_images_and_labels(test_filenames, test_labels)

# Entrena el modelo
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
loss_fn = torch.nn.CrossEntropyLoss()
epochs = 10
batch_size = 16
n_train = len(train_labels)

for epoch in range(epochs):
    model.train()
    for i in range(0, n_train, batch_size):
        optimizer.zero_grad()
        batch_images = train_images[i:i+batch_size]
        batch_labels = train_labels[i:i+batch_size]
        outputs = model(batch_images).logits
        loss = loss_fn(outputs, batch_labels)
        loss.backward()
        optimizer.step()
    model.eval()
    with torch.no_grad():
        inputs = feature_extractor(test_images, return_tensors='pt').pixel_values
        outputs = model(inputs)

import os
import random
import numpy as np
from sklearn.model_selection import train_test_split
import torch
import torchvision.transforms.functional as TF
import torchvision.transforms as transforms
from PIL import Image
from transformers import ViTFeatureExtractor, ViTForImageClassification


# Define la transformación para la entrada del modelo
transform = transforms.Compose([
    transforms.Resize(224),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Carga el modelo y el extractor de características
model = ViTForImageClassification.from_pretrained("google/vit-base-patch16-224")
feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')


# Define la función para cargar las imágenes y las etiquetas en el formato necesario para el modelo
def load_images_and_labels(filenames, labels):
    images = []
    for filename in filenames:
        try:
            image = Image.open(filename)
            image = transform(image)
            images.append(image)
        except:
            print(f"Error al cargar la imagen: {filename}")
    images = torch.stack(images)
    labels = torch.tensor(labels)
    return images, labels


# Convertir las imágenes a tensores
train_images_tensors = torch.stack(train_images)

# Carga las imágenes de entrenamiento y prueba y sus etiquetas
train_images, train_labels = load_images_and_labels(train_filenames, train_labels)
test_images, test_labels = load_images_and_labels(test_filenames, test_labels)

# Entrena el modelo
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
loss_fn = torch.nn.CrossEntropyLoss()
epochs = 10
batch_size = 16
n_train = len(train_labels)

for epoch in range(epochs):
    model.train()
    for i in range(0, n_train, batch_size):
        optimizer.zero_grad()
        batch_images = train_images_tensors[i:i+batch_size]
        batch_labels = train_labels[i:i+batch_size]
        outputs = model(batch_images).logits
        loss = loss_fn(outputs, batch_labels)
        loss.backward()
        optimizer.step()
    model.eval()
    with torch.no_grad():
        inputs = feature_extractor(test_images, return_tensors='pt').pixel_values
        outputs = model(inputs)

image = cv2.imread("/content/outside/-wfRXgxBGhXmxDlHkQhF2g.jpg")
cv2_imshow(image)

image.shape

def train_epoch(model, train_loader, optimizer):
    model.train()
    train_loss = 0.0
    train_acc = 0.0
    train_total = 0.0
    for batch in tqdm(train_loader):
        batch = {k: v.to(device) for k, v in batch.items()}
        optimizer.zero_grad()
        outputs = model(**batch)
        loss = outputs.loss
        logits = outputs.logits
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * batch["input_ids"].size(0)
        _, predicted = torch.max(logits, 1)
        train_acc += (predicted == batch["labels"]).sum().item()
        train_total += batch["labels"].size(0)
    train_loss = train_loss / train_total
    train_acc = train_acc / train_total
    return train_loss, train_acc

def eval_epoch(model, eval_loader):
    model.eval()
    eval_loss = 0.0
    eval_accuracy = 0.0
    nb_eval_steps = 0

    with torch.no_grad():
        for batch in eval_loader:
            batch = {k: v.to(device) for k, v in batch.items()}
            outputs = model(**batch)
            logits = outputs.logits
            labels = batch["labels"]
            loss = criterion(logits, labels)
            eval_loss += loss.item()
            eval_accuracy += (logits.argmax(dim=-1) == labels).float().sum().item()
            nb_eval_steps += 1

    eval_loss /= nb_eval_steps
    eval_accuracy /= len(eval_loader.dataset)

    return eval_loss, eval_accuracy

from transformers import ViTFeatureExtractor, ViTModel

api_key = "Tu_API_key_de_Hugging_Face"
model_id = "user/imagenet21k_ViT-B_16"

feature_extractor = ViTFeatureExtractor.from_pretrained(model_id, api_key=api_key)
model = ViTModel.from_pretrained(model_id, api_key=api_key)